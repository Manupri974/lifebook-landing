import fetch from "node-fetch";
import { config } from "dotenv";

config();
const apiKey = process.env.OPENAI_API_KEY;

export default async function genererLivre(req, res) {
  if (req.method !== "POST") {
    return res.status(405).json({ message: "M√©thode non autoris√©e" });
  }

  const { historique } = req.body;

  if (!apiKey || !historique || !Array.isArray(historique)) {
    return res.status(400).json({ message: "Cl√© API ou historique manquant/invalide" });
  }

  console.log("üöÄ G√©n√©ration du livre par s√©quences logiques...");

  // √âtape 1 : Grouper les messages utilisateur par s√©quence
  const sequences = {};
  let currentSequence = "1";

  for (const msg of historique) {
    if (msg.role === "assistant" && msg.content.includes("### S√©quence")) {
      const match = msg.content.match(/### S√©quence\s*:\s*(\d+)/i);
      if (match) {
        currentSequence = match[1];
        continue;
      }
    }

    if (msg.role === "user") {
      if (!sequences[currentSequence]) sequences[currentSequence] = [];
      sequences[currentSequence].push(msg.content.trim());
    }
  }

  console.log("üß© S√©quences logiques d√©tect√©es :", Object.keys(sequences).length);

  // √âtape 2 : G√©n√©rer un chapitre par s√©quence
  const promptSysteme = "Tu es un biographe litt√©raire, empathique, humain.";
  const promptChapitre = (bloc) => `Voici une s√©quence d‚Äôinterview biographique :

${bloc}

Ta mission :
- G√©n√®re un **chapitre fluide et narratif** √† partir de ces √©l√©ments.
- Commence par un **titre stylis√©** (niveau titre principal).
- Puis r√©dige un texte fluide, litt√©raire, chaleureux et r√©aliste √† la premi√®re ou troisi√®me personne.
- Utilise seulement les faits pr√©sents (pas d‚Äôinvention).
`;

  const chapitres = [];

  for (const numero in sequences) {
    const bloc = sequences[numero].join("\n\n");
    try {
      console.log(`üì§ Traitement s√©quence ${numero}...`);
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: "gpt-4o",
          temperature: 1.2,
          messages: [
            { role: "system", content: promptSysteme },
            { role: "user", content: promptChapitre(bloc) }
          ]
        })
      });

      const data = await response.json();
      const texte = data?.choices?.[0]?.message?.content;
      if (texte) {
        chapitres.push(texte.trim());
        console.log(`‚úÖ Chapitre ${numero} g√©n√©r√©`);
      } else {
        console.warn(`‚ö†Ô∏è Aucun texte g√©n√©r√© pour la s√©quence ${numero}`);
      }
    } catch (err) {
      console.error(`‚ùå Erreur sur la s√©quence ${numero} :`, err);
    }
  }

  const texteFinal = chapitres.join("\n\n");

  if (!texteFinal || texteFinal.length < 100) {
    return res.status(500).json({ message: "Le texte g√©n√©r√© est trop court ou vide." });
  }

  console.log("üìò Livre final g√©n√©r√© avec succ√®s.");
  res.status(200).json({ texte: texteFinal });
}
